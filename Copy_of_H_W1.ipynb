{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQKdAXUuhquWa4miGpiTbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rehab-04/ASU/blob/main/Copy_of_H_W1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C4nPtV78IYFg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://www.careopinion.org.uk/opinions/?page={}'\n",
        "def scrap_page(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "    about_link = soup.find_all('a', class_='font-c-1 tooltip')\n",
        "    story_titles = []\n",
        "    story_opinion = []\n",
        "    #list\n",
        "    story_hospitals = []\n",
        "    story_dates = []\n",
        "    story_comments = []\n",
        "    story_summaries = []\n",
        "    base_domain = 'https://www.careopinion.org.uk'\n",
        "    for link in about_link:\n",
        "        title = link.get_text(strip=True).replace('\"', '')\n",
        "        story_titles.append(title)\n",
        "        href = link.get('href')\n",
        "        if href:\n",
        "            full_url = base_domain + href\n",
        "            opinion_response = requests.get(full_url)\n",
        "            opinion_response.raise_for_status()\n",
        "            opinion_soup = BeautifulSoup(opinion_response.content, 'lxml')\n",
        "\n",
        "\n",
        "            hospital_tag = opinion_soup.find('span', class_='location-name')\n",
        "            hospital = hospital_tag.get_text(strip=True) if hospital_tag else 'Not there!'\n",
        "            story_hospitals.append(hospital)\n",
        "#==============================================================================================================\n",
        "            date_tag = opinion_soup.find('span', class_='date')\n",
        "            date = date_tag.get_text(strip=True) if date_tag else 'Not there!'\n",
        "            story_dates.append(date)\n",
        "#==============================================================================================================\n",
        "            opinion_tag = opinion_soup.find('blockquote', id='opinion_body')\n",
        "            o_text = opinion_tag.get_text(strip=True) if opinion_tag else 'Not there!'\n",
        "            story_opinion.append(o_text)\n",
        "#==============================================================================================================\n",
        "            comment_tag = opinion_soup.find('span', class_='count')\n",
        "            comments = comment_tag.get_text(strip=True) if comment_tag else 'Not there!'\n",
        "            story_comments.append(comments)\n",
        "#==============================================================================================================\n",
        "            summary_sections = opinion_soup.find_all('div', class_='feedback-section')\n",
        "            summary = []\n",
        "            for section in summary_sections:\n",
        "                question = section.find('h3')\n",
        "                answer = section.find('p')\n",
        "                if question and answer:\n",
        "                    summary.append(f\"{question.get_text(strip=True)}: {answer.get_text(strip=True)}\")\n",
        "            summary_text = ' | '.join(summary) if summary else 'Not there!'\n",
        "            story_summaries.append(summary_text)\n",
        "            time.sleep(2)\n",
        "    return story_titles, story_opinion, story_hospitals, story_dates, story_comments, story_summaries\n",
        "def scrape_all_pages(base_url, num_pages):\n",
        "    all_titles = []\n",
        "    all_opinions = []\n",
        "    all_hospitals = []\n",
        "    all_dates = []\n",
        "    all_comments = []\n",
        "    all_summaries = []\n",
        "\n",
        "    for page in range(1, num_pages + 1):\n",
        "        print(f'page num ={page}')\n",
        "        url = base_url.format(page)\n",
        "        titles, opinions, hospitals, dates, comments, summaries = scrap_page(url)\n",
        "        all_titles.extend(titles)\n",
        "        all_opinions.extend(opinions)\n",
        "        all_hospitals.extend(hospitals)\n",
        "        all_dates.extend(dates)\n",
        "        all_comments.extend(comments)\n",
        "        all_summaries.extend(summaries)\n",
        "    return all_titles, all_opinions, all_hospitals, all_dates, all_comments, all_summaries\n",
        "titles, opinions, hospitals, dates, comments, summaries = scrape_all_pages(base_url, 3)\n",
        "df = pd.DataFrame({\n",
        "    'Title': titles,\n",
        "    'Opinion': opinions,\n",
        "    'Hospital Name': hospitals,\n",
        "    'Date': dates,\n",
        "    'Number of Comments': comments,\n",
        "    'Story Summary': summaries\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df.to_csv('care_opinion_feedback.csv', index=False)\n",
        "print('finish')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDOWWOskJjTL",
        "outputId": "105b5acf-d4ea-42bc-a10a-6682c553fb9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page num =1\n",
            "page num =2\n",
            "page num =3\n",
            "finish\n"
          ]
        }
      ]
    }
  ]
}